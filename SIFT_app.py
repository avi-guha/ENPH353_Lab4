#!/usr/bin/env python3
# Requires: pip install opencv-contrib-python PyQt5

"""
@file
@brief PyQt5 + OpenCV SIFT matcher with homography overlay.

This module implements a desktop application that:
  - Captures frames from a webcam (OpenCV `cv2.VideoCapture`)
  - Detects and describes keypoints with SIFT (`cv2.SIFT_create().detectAndCompute`)
  - Matches template features to live-frame features with a BFMatcher + Lowe ratio test
  - Estimates a robust planar projective transform (homography) with RANSAC
  - Draws ONLY the homography polygon on the main UI once it is confidently found
  - Shows a popup window with a live match visualization (lines) and a good-match counter

Key OpenCV calls explained inline where used:
  - `cv2.VideoCapture` opens the camera device for frame grabbing.
  - `cv2.cvtColor` converts color spaces (e.g., BGR↔RGB, BGR→GRAY).
  - `cv2.SIFT_create` constructs a SIFT detector/descriptor (needs opencv-contrib).
  - `cv2.BFMatcher(...).knnMatch` finds the 2-NN matches per descriptor.
  - Lowe ratio test filters ambiguous matches by distance ratio m.distance/n.distance.
  - `cv2.findHomography(..., cv2.RANSAC, ...)` fits a robust projective transform.
  - `cv2.perspectiveTransform` maps template corners by the homography.
  - `cv2.polylines` draws the homography polygon.
  - `cv2.drawMatches` creates a composite match-visualization with lines.

PyQt5 widgets used:
  - `QMainWindow` main application window (hosts your pre-built .ui).
  - `QTimer` to poll the camera periodically on the GUI thread.
  - `QDialog` (tool window) for the live match-visualization popup.
  - `QLabel` to display images (via `setPixmap` with `QImage`/`QPixmap`).
  - `QFileDialog` to browse/select a template image.
"""

from PyQt5 import QtCore, QtGui, QtWidgets
from python_qt_binding import loadUi  # Loads a .ui file generated by Qt Designer into this window

import cv2
import numpy as np
import sys


class My_App(QtWidgets.QMainWindow):
    r"""
    @brief Main window: handles UI wiring, camera polling, SIFT, matching, and homography drawing.

    **Behavior**
    - The main UI shows a clean live camera view.
    - Once a homography is successfully found (>= MIN_GOOD_MATCHES and `H` is not `None`),
      the main UI draws **only** the blue homography polygon on top of the live frame.
    - The popup always shows the side-by-side matches with lines; if homography is
      available, the polygon is drawn on the live (right) side in the popup too.

    **Tuning**
    - `RATIO_TEST` is the Lowe ratio threshold (stricter if lower).
    - `MIN_GOOD_MATCHES` controls how many good matches are required before attempting a homography.
    - `RANSAC_REPROJ_THRESH` is the RANSAC reprojection error threshold (in pixels).
    """

    MIN_GOOD_MATCHES = 20            # Minimum "good" matches before attempting/accepting homography
    RATIO_TEST = 0.5                # Lowe ratio test threshold (smaller = stricter, e.g., 0.6–0.75 typical)
    RANSAC_REPROJ_THRESH = 5.0       # RANSAC reprojection threshold in pixels

    MATCH_W, MATCH_H = 900, 420      # Popup visualization canvas size
    CAM_W, CAM_H = 320, 240          # Camera capture resolution request

    def __init__(self):
        r"""
        @brief Initialize UI, camera, timers, SIFT, and popup.

        - `loadUi("./SIFT_app.ui", self)` injects the .ui widgets as attributes
           (e.g., `self.browse_button`, `self.toggle_cam_button`, `self.template_label`, `self.live_image_label`).
        - `cv2.VideoCapture(self._cam_id)` opens the default camera.
        - `QTimer` is connected to `SLOT_query_camera` to grab/process frames at `_cam_fps`.
        - SIFT detector (`cv2.SIFT_create`) and BFMatcher are created for feature matching.
        """
        super(My_App, self).__init__()
        loadUi("./SIFT_app.ui", self)

        # --- Camera config/state ---
        self._cam_id = 0
        self._cam_fps = 10
        self._is_cam_enabled = False
        self._is_template_loaded = False

        # --- Wire UI buttons to slots ---
        self.browse_button.clicked.connect(self.SLOT_browse_button)
        self.toggle_cam_button.clicked.connect(self.SLOT_toggle_camera)

        # --- OpenCV camera: request a small frame for speed/GUI ---
        self._camera_device = cv2.VideoCapture(self._cam_id)  # Open default camera (device 0)
        self._camera_device.set(cv2.CAP_PROP_FRAME_WIDTH, self.CAM_W)   # Request width
        self._camera_device.set(cv2.CAP_PROP_FRAME_HEIGHT, self.CAM_H)  # Request height

        # --- Periodic timer to fetch/process camera frames on the GUI thread ---
        self._timer = QtCore.QTimer(self)                      # Qt timer
        self._timer.timeout.connect(self.SLOT_query_camera)    # call on each tick
        self._timer.setInterval(int(1000 / self._cam_fps))     # ms interval for ~_cam_fps

        # --- SIFT + matcher (SIFT uses L2 norm; thus BFMatcher with NORM_L2) ---
        self.sift = cv2.SIFT_create(nfeatures=1500)            # SIFT detector/descriptor (needs opencv-contrib)
        self.bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False) # KNN requires crossCheck=False

        # --- Template fields (set after user loads an image) ---
        self.template_path = None
        self.template_img_gray = None
        self.template_img_color = None
        self.template_kp = None
        self.template_desc = None

        # --- Build the always-on-top match-visualization popup ---
        self._build_match_popup()

    # ---------- Popup construction & helpers ----------

    def _build_match_popup(self):
        r"""
        @brief Construct the non-modal, always-on-top popup with a match counter and an image canvas.

        - `QDialog` with @c Qt.Tool | @c Qt.WindowStaysOnTopHint so it floats above the main window.
        - `QLabel` (`self.match_label`) shows the live "good matches" count.
        - `QLabel` (`self.matches_view`) displays the composite from `cv2.drawMatches`.
        """
        self.match_dialog = QtWidgets.QDialog(self)
        self.match_dialog.setWindowTitle("SIFT Matches")
        self.match_dialog.setWindowFlags(
            self.match_dialog.windowFlags()
            | QtCore.Qt.Tool                  # Tool window style (doesn't appear in task bar)
            | QtCore.Qt.WindowStaysOnTopHint  # Always on top of the main window
        )
        self.match_dialog.setModal(False)      # Non-modal: doesn't block the main UI

        outer = QtWidgets.QVBoxLayout(self.match_dialog)

        # Count label (bold, centered)
        self.match_label = QtWidgets.QLabel("Good matches: 0 (need 40+)")
        self.match_label.setAlignment(QtCore.Qt.AlignCenter)
        f = self.match_label.font()
        f.setPointSize(12)
        f.setBold(True)
        self.match_label.setFont(f)
        outer.addWidget(self.match_label)

        # Single canvas that will show cv2.drawMatches output
        self.matches_view = QtWidgets.QLabel()
        self.matches_view.setAlignment(QtCore.Qt.AlignCenter)
        self.matches_view.setFixedSize(self.MATCH_W, self.MATCH_H)
        self.matches_view.setStyleSheet("border:1px solid #888; background:#111; color:#ccc;")
        outer.addWidget(self.matches_view)

        self.match_dialog.hide()

    def _bgr_to_pixmap_scaled(self, bgr_img, max_w, max_h):
        r"""
        @brief Convert a BGR NumPy image to a scaled QPixmap while preserving aspect ratio.

        @param bgr_img 3-channel uint8 image in BGR color order (OpenCV default).
        @param max_w Maximum width for scaling.
        @param max_h Maximum height for scaling.
        @return QPixmap scaled to fit within (max_w, max_h) using smooth/antialiased scaling.

        Steps:
          1. `cv2.cvtColor(..., cv2.COLOR_BGR2RGB)` converts BGR→RGB for Qt.
          2. `QImage` wraps the raw pixel buffer without copying.
          3. `QPixmap.fromImage` creates a paintable pixmap.
          4. `QPixmap.scaled(..., Qt.KeepAspectRatio, Qt.SmoothTransformation)` resizes nicely.
        """
        rgb = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2RGB)  # OpenCV BGR → RGB for Qt
        h, w, ch = rgb.shape
        qimg = QtGui.QImage(rgb.data, w, h, ch * w, QtGui.QImage.Format_RGB888)
        pm = QtGui.QPixmap.fromImage(qimg)
        return pm.scaled(max_w, max_h, QtCore.Qt.KeepAspectRatio, QtCore.Qt.SmoothTransformation)

    def _update_match_popup(self, vis_bgr, good_count):
        r"""
        @brief Update the popup with a new composite visualization and the current match count.

        @param vis_bgr Composite image (BGR) produced by `cv2.drawMatches`. If `None`, the
                       canvas is left unchanged.
        @param good_count Integer number of "good" matches that passed the Lowe ratio test.

        The label shows "OK" once `good_count >= MIN_GOOD_MATCHES`, otherwise "need 40+".
        """
        self.match_label.setText(
            f"Good matches: {good_count} "
            f"({'OK' if good_count >= self.MIN_GOOD_MATCHES else 'need 40+'})"
        )
        if vis_bgr is not None:
            self.matches_view.setPixmap(self._bgr_to_pixmap_scaled(vis_bgr, self.MATCH_W, self.MATCH_H))

    # ---------- UI helpers ----------

    def convert_cv_to_pixmap(self, cv_img_bgr):
        r"""
        @brief Convert BGR NumPy image to a QPixmap without scaling.

        @param cv_img_bgr 3-channel uint8 image in BGR.
        @return QPixmap with the same dimensions as the input array.

        Internals:
          - `cv2.cvtColor(..., cv2.COLOR_BGR2RGB)` for Qt's expected RGB byte order.
          - `QImage` created with a byte stride of `channels * width`.
        """
        cv_img = cv2.cvtColor(cv_img_bgr, cv2.COLOR_BGR2RGB)
        h, w, ch = cv_img.shape
        q_img = QtGui.QImage(cv_img.data, w, h, ch * w, QtGui.QImage.Format_RGB888)
        return QtGui.QPixmap.fromImage(q_img)

    # ---------- Slots ----------

    def SLOT_browse_button(self):
        r"""
        @brief Choose and load a template image; precompute its SIFT features.

        UI:
          - `QFileDialog` opens a file picker.
          - `self.template_label.setPixmap(...)` previews the chosen template in the main UI.

        OpenCV:
          - `cv2.imread(..., cv2.IMREAD_GRAYSCALE)` loads a single-channel image for SIFT.
          - `self.sift.detectAndCompute` extracts keypoints (`self.template_kp`) and descriptors
            (`self.template_desc`) from the template once to avoid recomputing each frame.
        """
        dlg = QtWidgets.QFileDialog(self)
        dlg.setFileMode(QtWidgets.QFileDialog.ExistingFile)
        if not dlg.exec_():
            return
        self.template_path = dlg.selectedFiles()[0]

        # Show template in the main UI (no overlays)
        self.template_label.setPixmap(QtGui.QPixmap(self.template_path))

        # Load template for OpenCV (gray for SIFT; also keep a color copy for drawMatches)
        self.template_img_gray = cv2.imread(self.template_path, cv2.IMREAD_GRAYSCALE)  # grayscale for SIFT
        if self.template_img_gray is None:
            QtWidgets.QMessageBox.warning(self, "Error", "Failed to load template.")
            return
        self.template_img_color = cv2.cvtColor(self.template_img_gray, cv2.COLOR_GRAY2BGR)  # for visualization

        # Precompute features on the template image (SIFT: scale/rotation-invariant descriptors)
        self.template_kp, self.template_desc = self.sift.detectAndCompute(self.template_img_gray, None)
        self._is_template_loaded = self.template_desc is not None and len(self.template_desc) > 0

        print(f"Loaded template: {self.template_path} (keypoints: {len(self.template_kp) if self.template_kp else 0})")

        if not self._is_template_loaded:
            QtWidgets.QMessageBox.information(self, "Template", "No SIFT features found in the template image.")
        else:
            QtWidgets.QMessageBox.information(self, "Template", "Template loaded and features computed.")
            # Initialize/clear popup canvas: make a blank composite until matches arrive
            blank = np.zeros(
                (self.CAM_H, self.CAM_W + (self.template_img_color.shape[1] if self.template_img_color is not None else self.CAM_W), 3),
                dtype=np.uint8
            )
            self._update_match_popup(blank, 0)

    def SLOT_query_camera(self):
        r"""
        @brief Periodic slot (via `QTimer`) that grabs a frame, matches features, and updates UI.

        Steps per tick:
          1. Grab a frame with `cv2.VideoCapture.read()`.
          2. If a template is loaded:
             - Convert frame to gray (`cv2.cvtColor`) and compute SIFT features.
             - Match template descriptors to frame descriptors with `BFMatcher.knnMatch(k=2)`.
             - Apply Lowe ratio test (`m.distance < RATIO_TEST * n.distance`) to filter matches.
             - If `len(good_matches) >= MIN_GOOD_MATCHES`, compute homography with
               `cv2.findHomography(..., cv2.RANSAC, RANSAC_REPROJ_THRESH)`.
             - If homography `H` is valid, project template corners (`cv2.perspectiveTransform`) and
               draw a blue polygon (`cv2.polylines`) on:
                 - the popup overlay copy (for visualization),
                 - the main UI frame (ONLY the polygon, no match lines) **once found**.
             - Build the side-by-side composite using `cv2.drawMatches` for the popup and
               overlay the count with `cv2.putText`.
          3. Update the main QLabel with a clean frame unless a polygon is available.

        @note We keep the main view uncluttered; matches are shown only in the popup.
        """
        ok, frame = self._camera_device.read()  # Grab a frame from the camera
        if not ok:
            return

        # By default, main UI shows clean frame
        main_display = frame.copy()

        # --- POPUP: compute matches and draw only there ---
        vis_bgr = None
        good_matches = []
        homography_found = False
        proj_polygon = None  # to draw on main UI only if found

        if self._is_template_loaded:
            # 1) Detect SIFT features on the live frame
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)            # Convert BGR→GRAY for SIFT
            kp_frame, desc_frame = self.sift.detectAndCompute(gray, None)  # Keypoints & descriptors on frame

            if desc_frame is not None and len(desc_frame) > 0:
                # 2) KNN match: for each template descriptor, find its two nearest neighbors in the frame
                raw_matches = self.bf.knnMatch(self.template_desc, desc_frame, k=2)

                # 3) Lowe ratio test: keep matches that are much better than the 2nd-best candidate
                for m, n in raw_matches:
                    if m.distance < self.RATIO_TEST * n.distance:
                        good_matches.append(m)

                # Prepare an overlay copy of the live frame for the POPUP only
                overlay_frame = frame.copy()

                # 4) If enough good matches, estimate a robust homography with RANSAC
                if len(good_matches) >= self.MIN_GOOD_MATCHES:
                    src_pts = np.float32([self.template_kp[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)
                    dst_pts = np.float32([kp_frame[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)

                    # cv2.findHomography: estimates a 3x3 projective transform T such that  x' ~ T x
                    # Using RANSAC reduces the influence of outliers among matches.
                    H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, self.RANSAC_REPROJ_THRESH)
                    if H is not None:
                        # Project template's 4-corner rectangle into the frame
                        h, w = self.template_img_gray.shape
                        corners = np.float32([[0, 0], [0, h - 1], [w - 1, h - 1], [w - 1, 0]]).reshape(-1, 1, 2)
                        proj = cv2.perspectiveTransform(corners, H)  # Apply homography to corners

                        # Draw polygon on the POPUP image (right side) for visualization
                        cv2.polylines(overlay_frame, [np.int32(proj)], True, (255, 0, 0), 3, cv2.LINE_AA)

                        # Save for MAIN UI draw (only polygon, no lines)
                        homography_found = True
                        proj_polygon = np.int32(proj)

                # 5) Build the side-by-side matches WITH lines (and polygon if drawn above) for the popup
                # cv2.drawMatches stitches template (left) and frame (right) and draws match lines.
                vis_bgr = cv2.drawMatches(
                    self.template_img_color, self.template_kp,
                    overlay_frame, kp_frame if kp_frame is not None else [],
                    good_matches, None,
                    flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS
                )
                # Overlay a simple counter label on the composite
                cv2.putText(
                    vis_bgr,
                    f"Good matches: {len(good_matches)} (need {self.MIN_GOOD_MATCHES}+ for Homography)",
                    (10, 28), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 200, 0), 2, cv2.LINE_AA
                )

        # Update popup (even if no descriptors found)
        if vis_bgr is None:
            blank = np.zeros(
                (self.CAM_H, self.CAM_W + (self.template_img_color.shape[1] if self.template_img_color is not None else self.CAM_W), 3),
                dtype=np.uint8
            )
            self._update_match_popup(blank, 0)
        else:
            self._update_match_popup(vis_bgr, len(good_matches))

        # --- MAIN UI: draw ONLY the homography polygon if found; else keep the frame clean ---
        if homography_found and proj_polygon is not None:
            # cv2.polylines draws the blue quadrilateral on the live frame only (no match lines)
            cv2.polylines(main_display, [proj_polygon], True, (255, 0, 0), 3, cv2.LINE_AA)

        # Convert BGR→RGB and push to the Qt label
        self.live_image_label.setPixmap(self.convert_cv_to_pixmap(main_display))

    def SLOT_toggle_camera(self):
        r"""
        @brief Toggle the camera polling and show/hide the popup accordingly.

        - Starts/stops the `QTimer` that drives `SLOT_query_camera`.
        - Updates the toggle button text.
        - Shows the match popup when enabled, hides it when disabled.
        """
        if self._is_cam_enabled:
            self._timer.stop()
            self._is_cam_enabled = False
            self.toggle_cam_button.setText("&Enable camera")
            self.match_dialog.hide()
        else:
            self._timer.start()
            self._is_cam_enabled = True
            self.toggle_cam_button.setText("&Disable camera")
            self.match_dialog.show()

    def closeEvent(self, event):
        r"""
        @brief Qt close handler: release camera resources and accept the event.

        @param event `QCloseEvent` dispatched by Qt when the window is closing.
        """
        try:
            if self._camera_device and self._camera_device.isOpened():
                self._camera_device.release()  # Release OS handle to the camera
        finally:
            event.accept()


if __name__ == "__main__":
    """
    @brief Qt application entry-point.

    - Construct the `QApplication` (required by any Qt GUI).
    - Instantiate and show `My_App`.
    - Enter the Qt main event loop with `app.exec_()`.
    """
    app = QtWidgets.QApplication(sys.argv)
    myApp = My_App()
    myApp.show()
    sys.exit(app.exec_())
